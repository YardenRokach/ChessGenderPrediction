{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0255c7a-86e0-4556-a62c-83742a21ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras import Input, Model, Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding, Concatenate, Conv1D, Lambda, Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input, Concatenate, Flatten, Dot, Dropout\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.metrics import AUC\n",
    "import numpy as np\n",
    "import glob\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bd5eca-381f-4191-b4b7-71e71caff5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "def conv_vit(num_layers, num_heads, dropout_rate):\n",
    "    size = 4 * 4 * 64\n",
    "    \n",
    "    inputs = keras.Input(shape=(20, 8, 8, 34))\n",
    "\n",
    "    # Convolutional patch embedding\n",
    "    x = Conv2D(filters=16, kernel_size=(5, 5), activation='relu', padding='same')(inputs)\n",
    "    x = Conv2D(filters=16, kernel_size=(4, 4), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(2, 2), activation='relu')(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(2, 2), activation='relu')(x)    \n",
    "    x = layers.Reshape((20, 4 * 4 * 64))(x)\n",
    "\n",
    "    # Positional embedding\n",
    "    pos_emb = layers.Embedding(input_dim=20, output_dim=size)(K.constant(np.asarray(range(0, 20))))\n",
    "    pos_emb = tf.expand_dims(pos_emb, axis=0)\n",
    "    pos_emb = tf.tile(pos_emb, [tf.shape(inputs)[0], 1, 1])  # Tile the tensor to match the desired batch size    \n",
    "    x = layers.Add()([x, pos_emb])\n",
    "    \n",
    "    \n",
    "\n",
    "    # Transformer Encoder\n",
    "    for _ in range(num_layers):\n",
    "        # Multi-Head Self-Attention\n",
    "        y = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        y = layers.MultiHeadAttention(num_heads=num_heads, key_dim=size, dropout=dropout_rate)(y, y)\n",
    "        y = layers.Add()([x, y])\n",
    "\n",
    "        # Feed Forward Neural Network\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(y)\n",
    "        x = layers.Dense(1024, activation='relu')(x)\n",
    "        x = layers.Dense(1024, activation='relu')(x)\n",
    "        x = layers.Add()([y, x])\n",
    "\n",
    "    # Classifier head\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        metrics=['accuracy', AUC(curve='ROC')],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2aff46-a366-4de4-88ee-9f3b220c5457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 17:35:43.740482: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-25 17:35:53.313537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10405 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model = conv_vit(3, 16, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52e18001-261c-4229-9fee-f3f8b3177579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_last(string, word_to_replace, replacement):\n",
    "    split_string = string.rsplit(word_to_replace, 1)\n",
    "    return replacement.join(split_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeb972a8-5394-49d6-8fe0-f29e6128173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "#Function to clean keras cache to allow calling the 'fit' function multiple times\n",
    "def reset_keras(model):\n",
    "    sess = K.get_session()\n",
    "    K.clear_session()\n",
    "    sess.close()\n",
    "    sess = K.get_session()\n",
    "\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e03d43e-55a0-40d7-b29e-b15f18abf324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195572, 20, 8, 8, 34)\n",
      "(195572,)\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('/sise/liorrk-group/DataSets/Datamining/xs_data/xs*')\n",
    "#First data file used for test set\n",
    "Xs_test = np.load(files[0], allow_pickle=True) #Use first file for testing\n",
    "ys_test = np.load(replace_last(files[0], 'xs', 'ys'), allow_pickle=True)\n",
    "\n",
    "print(Xs_test.shape)\n",
    "print(ys_test.shape)\n",
    "\n",
    "def model_train_epoch():\n",
    "    #Train set too big to load all at once, load each file separately and train, skip first file as it is for testing\n",
    "    global model\n",
    "    for file in files[1:]:\n",
    "        Xs_train = np.load(file, allow_pickle=True)\n",
    "        ys_train = np.load(replace_last(file, 'xs', 'ys'), allow_pickle=True)\n",
    "        print(Xs_train.shape)\n",
    "        print(ys_train.shape)\n",
    "        #Reload model before each 'fit' call due to keras memory leak\n",
    "        model.save(\"my_model\")\n",
    "        reset_keras(model)    \n",
    "        model = load_model(\"my_model\")\n",
    "        \n",
    "        model.fit(Xs_train, ys_train, epochs=1, batch_size=64)\n",
    "        del Xs_train\n",
    "        del ys_train\n",
    "        gc.collect()    \n",
    "    score = model.evaluate(Xs_test, ys_test)\n",
    "    print(f'Test set evaluation: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ac76e-1cb2-4268-a20d-1f5d774b65d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch_count = 10\n",
    "for i in range(epoch_count):\n",
    "    model_train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59078fce-85b6-4f96-9c77-aa1e2c2fb19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 18:10:35.233952: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-25 18:10:35.692460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46503 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:61:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d3df1f4-bdd2-4f21-83c6-8200944c4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1977953a-0804-44df-aff5-afaa63480a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 18:11:52.791571: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-06-25 18:12:03.188228: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8401\n",
      "2023-06-25 18:12:04.637999: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5972911886234157\n",
      "AUC-PR: 0.16229304492045582\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(Xs_test)\n",
    "\n",
    "auc = roc_auc_score(ys_test, y_pred)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "auc_pr = average_precision_score(ys_test, y_pred)\n",
    "print(\"AUC-PR:\", auc_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f3394-307e-4697-abdb-56579d607fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
